{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T07:50:39.057633Z",
     "iopub.status.busy": "2024-03-12T07:50:39.057031Z",
     "iopub.status.idle": "2024-03-12T07:50:46.659914Z",
     "shell.execute_reply": "2024-03-12T07:50:46.658919Z",
     "shell.execute_reply.started": "2024-03-12T07:50:39.057591Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import datasets\n",
    "from datasets import Dataset\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "\n",
    "from collections import Counter\n",
    "from typing import List, Callable\n",
    "import string\n",
    "import torch.nn.functional as nnf\n",
    "import json\n",
    "\n",
    "import seaborn\n",
    "seaborn.set(palette='summer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T07:54:41.961050Z",
     "iopub.status.busy": "2024-03-12T07:54:41.959903Z",
     "iopub.status.idle": "2024-03-12T07:55:01.905607Z",
     "shell.execute_reply": "2024-03-12T07:55:01.904561Z",
     "shell.execute_reply.started": "2024-03-12T07:54:41.960999Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/kaggle/working/avito_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-12T07:55:01.909427Z",
     "iopub.status.busy": "2024-03-12T07:55:01.909033Z",
     "iopub.status.idle": "2024-03-12T07:55:01.917325Z",
     "shell.execute_reply": "2024-03-12T07:55:01.916123Z",
     "shell.execute_reply.started": "2024-03-12T07:55:01.909399Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:17.134820Z",
     "iopub.status.busy": "2024-03-11T17:45:17.134486Z",
     "iopub.status.idle": "2024-03-11T17:45:18.121186Z",
     "shell.execute_reply": "2024-03-11T17:45:18.119882Z",
     "shell.execute_reply.started": "2024-03-11T17:45:17.134793Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data['str_len']=train_data.description.str.len()\n",
    "train_data.rename(columns={'Unnamed: 0': 'idxs'}, inplace=True)\n",
    "train_data.rename(columns={'description': 'text', 'is_bad': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:18.122937Z",
     "iopub.status.busy": "2024-03-11T17:45:18.122537Z",
     "iopub.status.idle": "2024-03-11T17:45:25.485389Z",
     "shell.execute_reply": "2024-03-11T17:45:25.484051Z",
     "shell.execute_reply.started": "2024-03-11T17:45:18.122906Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_dict = train_data[:-64000][['text', 'label']].to_dict('list')\n",
    "# test_dict = train_data[-64000:][['text', 'label']].to_dict('list')\n",
    "# train_d = Dataset.from_dict(data_dict)\n",
    "# test_d = Dataset.from_dict(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.487420Z",
     "iopub.status.busy": "2024-03-11T17:45:25.486962Z",
     "iopub.status.idle": "2024-03-11T17:45:25.565083Z",
     "shell.execute_reply": "2024-03-11T17:45:25.563910Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.487390Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/d/emilte/dictionaries-avito/ind2word.json') as json_file:\n",
    "    ind2word = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.567504Z",
     "iopub.status.busy": "2024-03-11T17:45:25.566405Z",
     "iopub.status.idle": "2024-03-11T17:45:25.633181Z",
     "shell.execute_reply": "2024-03-11T17:45:25.632204Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.567463Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('/kaggle/input/d/emilte/dictionaries-avito/word2ind.json') as json_file:\n",
    "    word2ind = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.634940Z",
     "iopub.status.busy": "2024-03-11T17:45:25.634430Z",
     "iopub.status.idle": "2024-03-11T17:45:25.639069Z",
     "shell.execute_reply": "2024-03-11T17:45:25.638110Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.634912Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = word2ind.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T11:45:20.141096Z",
     "iopub.status.busy": "2024-03-11T11:45:20.140617Z",
     "iopub.status.idle": "2024-03-11T11:45:20.153519Z",
     "shell.execute_reply": "2024-03-11T11:45:20.151832Z",
     "shell.execute_reply.started": "2024-03-11T11:45:20.141062Z"
    }
   },
   "outputs": [],
   "source": [
    "words = Counter()\n",
    "\n",
    "for example in tqdm(train_data['text']):\n",
    "    # Приводим к нижнему регистру и убираем пунктуацию\n",
    "    prccessed_text = example.lower().translate(\n",
    "        str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    for word in word_tokenize(prccessed_text):\n",
    "        words[word] += 1\n",
    "\n",
    "\n",
    "vocab = set(['<unk>', '<bos>', '<eos>', '<pad>'])\n",
    "counter_threshold = 128\n",
    "\n",
    "for char, cnt in words.items():\n",
    "    if cnt > counter_threshold:\n",
    "        vocab.add(char)\n",
    "\n",
    "print(f'Размер словаря: {len(vocab)}')\n",
    "\n",
    "word2ind = {char: i for i, char in enumerate(vocab)}\n",
    "ind2word = {i: char for char, i in word2ind.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T11:45:20.159755Z",
     "iopub.status.busy": "2024-03-11T11:45:20.159142Z",
     "iopub.status.idle": "2024-03-11T11:45:20.166675Z",
     "shell.execute_reply": "2024-03-11T11:45:20.165012Z",
     "shell.execute_reply.started": "2024-03-11T11:45:20.159704Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('word2ind.json', 'w') as fp:\n",
    "    json.dump(word2ind, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T11:45:20.168755Z",
     "iopub.status.busy": "2024-03-11T11:45:20.168230Z",
     "iopub.status.idle": "2024-03-11T11:45:20.177568Z",
     "shell.execute_reply": "2024-03-11T11:45:20.176303Z",
     "shell.execute_reply.started": "2024-03-11T11:45:20.168716Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('ind2word.json', 'w') as fps:\n",
    "    json.dump(ind2word, fps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.643330Z",
     "iopub.status.busy": "2024-03-11T17:45:25.642683Z",
     "iopub.status.idle": "2024-03-11T17:45:25.659143Z",
     "shell.execute_reply": "2024-03-11T17:45:25.657730Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.643299Z"
    }
   },
   "outputs": [],
   "source": [
    "class WordDataset:\n",
    "    def __init__(self, sentences):\n",
    "        self.data = sentences\n",
    "        self.unk_id = word2ind['<unk>']\n",
    "        self.bos_id = word2ind['<bos>']\n",
    "        self.eos_id = word2ind['<eos>']\n",
    "        self.pad_id = word2ind['<pad>']\n",
    "\n",
    "    def __getitem__(self, idx: int) -> List[int]:\n",
    "        processed_text = self.data[idx]['text'].lower().translate(\n",
    "            str.maketrans('', '', string.punctuation))\n",
    "        tokenized_sentence = [self.bos_id]\n",
    "        tokenized_sentence += [\n",
    "            word2ind.get(word, self.unk_id) for word in word_tokenize(processed_text)\n",
    "            ]\n",
    "        tokenized_sentence += [self.eos_id]\n",
    "\n",
    "        train_sample = {\n",
    "            \"text\": tokenized_sentence,\n",
    "            \"label\": self.data[idx]['label']\n",
    "        }\n",
    "\n",
    "        return train_sample\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "def collate_fn_with_padding(\n",
    "    input_batch: List[List[int]], pad_id=word2ind['<pad>'], max_len=1024) -> torch.Tensor:\n",
    "    seq_lens = [len(x['text']) for x in input_batch]\n",
    "    max_seq_len = min(max(seq_lens), max_len)\n",
    "\n",
    "    new_batch = []\n",
    "    for sequence in input_batch:\n",
    "        sequence['text'] = sequence['text'][:max_seq_len]\n",
    "        for _ in range(max_seq_len - len(sequence['text'])):\n",
    "            sequence['text'].append(pad_id)\n",
    "\n",
    "        new_batch.append(sequence['text'])\n",
    "\n",
    "    sequences = torch.LongTensor(new_batch).to(device)\n",
    "    labels = torch.LongTensor([x['label'] for x in input_batch]).to(device)\n",
    "\n",
    "    new_batch = {\n",
    "        'input_ids': sequences,\n",
    "        'label': labels\n",
    "    }\n",
    "\n",
    "    return new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.661123Z",
     "iopub.status.busy": "2024-03-11T17:45:25.660801Z",
     "iopub.status.idle": "2024-03-11T17:45:25.700276Z",
     "shell.execute_reply": "2024-03-11T17:45:25.699371Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.661097Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = WordDataset(train_d)\n",
    "\n",
    "idx = np.random.choice(np.arange(len(test_d)), 32000)\n",
    "eval_dataset = WordDataset(test_d.select(idx))\n",
    "\n",
    "pred_dataset = WordDataset(train_d)\n",
    "\n",
    "idx2 = np.random.choice(np.arange(len(test_d)), 64)\n",
    "debug_dataset = WordDataset(test_d.select(idx2))\n",
    "\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n",
    "\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, shuffle=False, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n",
    "\n",
    "pred_dataloader = DataLoader(\n",
    "    pred_dataset, shuffle=False, collate_fn=collate_fn_with_padding, batch_size=batch_size)\n",
    "\n",
    "debug_dataloader = DataLoader(\n",
    "    debug_dataset, shuffle=False, collate_fn=collate_fn_with_padding, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.702954Z",
     "iopub.status.busy": "2024-03-11T17:45:25.701776Z",
     "iopub.status.idle": "2024-03-11T17:45:25.713345Z",
     "shell.execute_reply": "2024-03-11T17:45:25.712072Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.702912Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, eval_dataloader) -> float:\n",
    "    \"\"\"\n",
    "    Calculate accuracy on validation dataloader.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "    target = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            logits = model(batch['input_ids'])\n",
    "            predictions.append(logits.argmax(dim=1))\n",
    "            target.append(batch['label'])\n",
    "\n",
    "    predictions = torch.cat(predictions)\n",
    "    target = torch.cat(target)\n",
    "    accuracy = (predictions == target).float().mean().item()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.715692Z",
     "iopub.status.busy": "2024-03-11T17:45:25.715064Z",
     "iopub.status.idle": "2024-03-11T17:45:25.729241Z",
     "shell.execute_reply": "2024-03-11T17:45:25.728084Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.715643Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, eval_dataloader) -> float:\n",
    "    \"\"\"\n",
    "    Calculate accuracy on validation dataloader.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_dataloader:\n",
    "            logits = model(batch['input_ids'])\n",
    "            predictions.append(logits.argmax(dim=1))\n",
    "\n",
    "    predictions = torch.cat(predictions)\n",
    "    \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.732292Z",
     "iopub.status.busy": "2024-03-11T17:45:25.731249Z",
     "iopub.status.idle": "2024-03-11T17:45:25.743128Z",
     "shell.execute_reply": "2024-03-11T17:45:25.742029Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.732251Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_proba(model, pred_dataloader) -> List:\n",
    "    \"\"\"\n",
    "    Calculate accuracy on validation dataloader.\n",
    "    \"\"\"\n",
    "\n",
    "    predictions = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in pred_dataloader:\n",
    "            logits = model(batch['input_ids'])\n",
    "            probs = nnf.softmax(logits, dim=1)\n",
    "            predictions.append(probs[:,1]) # BINARY - change for num_cat\n",
    "    \n",
    "    predictions = torch.cat(predictions)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.745418Z",
     "iopub.status.busy": "2024-03-11T17:45:25.744726Z",
     "iopub.status.idle": "2024-03-11T17:45:25.761419Z",
     "shell.execute_reply": "2024-03-11T17:45:25.760470Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.745380Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model: Callable,\n",
    "          train_loader: DataLoader,\n",
    "          eval_loader: DataLoader,\n",
    "          num_epochs: int = 2,\n",
    "          optimizer: torch.optim.Optimizer = None,\n",
    "          criterion = None,\n",
    "          scheduler: Callable = None,\n",
    "          device: str = 'cuda'):\n",
    "\n",
    "    eval_steps = len(train_dataloader) // 2\n",
    "\n",
    "    # в качестве значений по умолчанию используются параметры из самого ноутбука\n",
    "    if optimizer is None:\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    if criterion is None:\n",
    "        criterion = nn.CrossEntropyLoss(ignore_index=word2ind['<pad>'])\n",
    "\n",
    "    acc = []\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_losses = []\n",
    "        model.train()\n",
    "\n",
    "        for i, batch in enumerate(tqdm(train_loader, desc=f'Training epoch {epoch}:')):\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(batch['input_ids'])\n",
    "            loss = criterion(logits, batch['label'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "            if i % eval_steps == 0:\n",
    "                model.eval()\n",
    "                acc.append(evaluate(model, eval_loader))\n",
    "                model.train()\n",
    "\n",
    "        # если у нас есть scheduler, то мы его применем\n",
    "        if not scheduler is None:\n",
    "            scheduler.step()\n",
    "\n",
    "    losses.append(sum(epoch_losses) / len(epoch_losses))\n",
    "    \n",
    "    print (\"Accuracy:\", acc)\n",
    "    print (\"Losses:\", losses)\n",
    "    return acc, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.763966Z",
     "iopub.status.busy": "2024-03-11T17:45:25.763279Z",
     "iopub.status.idle": "2024-03-11T17:45:25.778042Z",
     "shell.execute_reply": "2024-03-11T17:45:25.776744Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.763927Z"
    }
   },
   "outputs": [],
   "source": [
    "class CharLM(nn.Module):\n",
    "    def __init__(\n",
    "        self, hidden_dim: int, vocab_size: int, num_classes: int = 2,\n",
    "        aggregation_type: str = 'max'\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.rnn = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.linear = nn.Linear(hidden_dim*2, hidden_dim)\n",
    "        self.projection = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "        self.non_lin = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.15)\n",
    "\n",
    "        self.aggregation_type = aggregation_type\n",
    "\n",
    "    def forward(self, input_batch) -> torch.Tensor:\n",
    "        embeddings = self.embedding(input_batch)  # [batch_size, seq_len, hidden_dim]\n",
    "        output, _ = self.rnn(embeddings)  # [batch_size, seq_len, hidden_dim]\n",
    "\n",
    "        if self.aggregation_type == 'max':\n",
    "            output = output.max(dim=1)[0] #[batch_size, hidden_dim]\n",
    "        elif self.aggregation_type == 'mean':\n",
    "            output = output.mean(dim=1) #[batch_size, hidden_dim]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid aggregation_type\")\n",
    "\n",
    "        output = self.dropout(self.relu(self.linear(self.non_lin(output))))  # [batch_size, hidden_dim]\n",
    "        prediction = self.projection(self.non_lin(output))  # [batch_size, num_classes]\n",
    "\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T09:04:09.407710Z",
     "iopub.status.busy": "2024-03-11T09:04:09.407429Z",
     "iopub.status.idle": "2024-03-11T09:04:11.869051Z",
     "shell.execute_reply": "2024-03-11T09:04:11.868082Z",
     "shell.execute_reply.started": "2024-03-11T09:04:09.407689Z"
    }
   },
   "outputs": [],
   "source": [
    "model = CharLM(hidden_dim=256, vocab_size=len(vocab), aggregation_type = 'mean').to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=word2ind['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model=model,\n",
    "      train_loader=train_dataloader,\n",
    "      eval_loader=eval_dataloader,\n",
    "      num_epochs=2,\n",
    "      optimizer=optimizer,\n",
    "      criterion=criterion,\n",
    "      device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save('cpu2_model_scripted.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'cpu2_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:45:25.780467Z",
     "iopub.status.busy": "2024-03-11T17:45:25.779932Z",
     "iopub.status.idle": "2024-03-11T17:45:26.401383Z",
     "shell.execute_reply": "2024-03-11T17:45:26.400215Z",
     "shell.execute_reply.started": "2024-03-11T17:45:25.780427Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model2 = CharLM(hidden_dim=256, vocab_size=len(vocab), aggregation_type = 'mean').to(device)\n",
    "model2.load_state_dict(torch.load('/kaggle/input/lstm-avito/pytorch/mb_working/1/cpu2_model.pt', map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T20:18:13.227358Z",
     "iopub.status.busy": "2024-03-11T20:18:13.226303Z",
     "iopub.status.idle": "2024-03-11T20:18:14.059850Z",
     "shell.execute_reply": "2024-03-11T20:18:14.058536Z",
     "shell.execute_reply.started": "2024-03-11T20:18:13.227318Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9375"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model2, debug_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T17:47:22.051389Z",
     "iopub.status.busy": "2024-03-11T17:47:22.050987Z",
     "iopub.status.idle": "2024-03-11T20:18:13.220664Z",
     "shell.execute_reply": "2024-03-11T20:18:13.219497Z",
     "shell.execute_reply.started": "2024-03-11T17:47:22.051358Z"
    }
   },
   "outputs": [],
   "source": [
    "probs = predict_proba(model2, pred_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T20:26:25.266380Z",
     "iopub.status.busy": "2024-03-11T20:26:25.265683Z",
     "iopub.status.idle": "2024-03-11T20:26:25.386892Z",
     "shell.execute_reply": "2024-03-11T20:26:25.385246Z",
     "shell.execute_reply.started": "2024-03-11T20:26:25.266334Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = train_data[:-64000].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T20:27:18.071877Z",
     "iopub.status.busy": "2024-03-11T20:27:18.070675Z",
     "iopub.status.idle": "2024-03-11T20:27:18.078809Z",
     "shell.execute_reply": "2024-03-11T20:27:18.077601Z",
     "shell.execute_reply.started": "2024-03-11T20:27:18.071819Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['probs'] = probs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['phones_loc'] = [[] for _ in range(len(dataset))]\n",
    "for i in range(len(dataset['text'])):\n",
    "    text = dataset.iloc[i, 2]  \n",
    "    for m in re.finditer(r'(?:8|\\+|9)[\\- ]?(?:\\(?\\d{3}\\)?[\\- ]?)?[\\d\\- ]{7,10}', text):\n",
    "        dataset.iloc[i, 9].append([m.start(), m.end()])\n",
    "        \n",
    "        \n",
    "dataset['link_mail_loc'] = [[] for _ in range(len(dataset))]\n",
    "for i in range(len(dataset['text'])):\n",
    "    text = dataset.iloc[i, 2]  \n",
    "    for m in re.finditer(r'(https?://)?\\s*([a-zA-Z0-9-]+\\. (ru|com|org|me))\\s*/\\s*([a-zA-Z0-9/]*)', text):\n",
    "        dataset.iloc[i, 10].append([m.start(), m.end()])\n",
    "        \n",
    "\n",
    "dataset['nick_loc'] = [[] for _ in range(len(dataset))] \n",
    "for i in range(len(dataset['text'])):\n",
    "    text = dataset.iloc[i, 2]  \n",
    "    for m in re.finditer(r'@[\\w]+', text):\n",
    "        dataset.iloc[i, 13].append([m.start(), m.end()])\n",
    "        \n",
    "dataset['link_mail_count'] = [len(i) for i in dataset['link_mail_loc']]\n",
    "dataset['phone_count'] = [len(i) for i in dataset['phones_loc']]\n",
    "dataset['nick_count'] = [len(i) for i in dataset['nick_loc']]\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    if dataset.iloc[i, dataset.columns.get_loc('phone_count')] > 0:\n",
    "        dataset.iloc[i, dataset.columns.get_loc('start')] = dataset.iloc[i, dataset.columns.get_loc('phones_loc')][0][0]\n",
    "        dataset.iloc[i, dataset.columns.get_loc('end')] = dataset.iloc[i, dataset.columns.get_loc('phones_loc')][0][1]\n",
    "        \n",
    "    elif dataset.iloc[i, dataset.columns.get_loc('nick_count')] > 0:\n",
    "        dataset.iloc[i, dataset.columns.get_loc('start')] = dataset.iloc[i, dataset.columns.get_loc('nick_loc')][0][0]\n",
    "        dataset.iloc[i, dataset.columns.get_loc('end')] = dataset.iloc[i, dataset.columns.get_loc('nick_loc')][0][1]\n",
    "        \n",
    "    elif dataset.iloc[i, dataset.columns.get_loc('link_mail_count')] > 0:\n",
    "        dataset.iloc[i, dataset.columns.get_loc('start')] = dataset.iloc[i, dataset.columns.get_loc('link_mail_loc')][0][0]\n",
    "        dataset.iloc[i, dataset.columns.get_loc('end')] = dataset.iloc[i, dataset.columns.get_loc('link_mail_loc')][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T20:31:32.100420Z",
     "iopub.status.busy": "2024-03-11T20:31:32.100010Z",
     "iopub.status.idle": "2024-03-11T20:32:09.716932Z",
     "shell.execute_reply": "2024-03-11T20:32:09.715744Z",
     "shell.execute_reply.started": "2024-03-11T20:31:32.100391Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.to_csv('/kaggle/working/avito_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T20:45:09.656758Z",
     "iopub.status.busy": "2024-03-11T20:45:09.655629Z",
     "iopub.status.idle": "2024-03-11T20:45:09.665368Z",
     "shell.execute_reply": "2024-03-11T20:45:09.664347Z",
     "shell.execute_reply.started": "2024-03-11T20:45:09.656711Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='avito_dataset.csv' target='_blank'>avito_dataset.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/avito_dataset.csv"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'../working')\n",
    "from IPython.display import FileLink\n",
    "FileLink(r'avito_dataset.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4564502,
     "sourceId": 7822285,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 12892,
     "sourceId": 15494,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
